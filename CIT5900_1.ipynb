{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Oqwddr3FlnM3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/n1xd/5900/blob/main/CIT5900_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "Lhm5NoUGY2nI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the GitHub data from [here](https://github.com/dingkaihua/fsrdc-external-census-projects/blob/master/ResearchOutputs.xlsx).\n",
        "\n",
        " We chose `pandas` and `dataframes` to process the `xlsx` file due to the library's simple nature when it comes to manipulating (i.e. selecting, renaming, singling-out, etc.) columns of data. We chose `KeyBERT` to produce keywords because of its ability to extract relevant keywords from the provided text using embeddings, which can filter function and irrelevant words more comprehensively than manual filtering."
      ],
      "metadata": {
        "id": "ITERs5-sdSX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LauipISYzxe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # import pandas for data analysis\n",
        "\n",
        "file_name = 'ResearchOutputs.xlsx'\n",
        "sheet_name = 'Sheet1'\n",
        "expected_columns = [\"OutputTitle\", \"OutputYear\", \"ProjectRDC\"]\n",
        "\n",
        "try:\n",
        "  df = pd.read_excel(file_name, sheet_name=sheet_name) # navigate to the file\n",
        "  missing_columns = [col for col in expected_columns if col not in df.columns]\n",
        "  if missing_columns: # raises error if these columns are not present\n",
        "    print(f\"Error: Missing required columns: {', '.join(missing_columns)} in '{file_name}' (Sheet: {sheet_name})\")\n",
        "  else:\n",
        "    rdc_data = df[expected_columns] # only use expected columns, except if not found\n",
        "    rdc_data = rdc_data.rename(columns={\n",
        "      \"OutputTitle\": \"title\",\n",
        "      \"OutputYear\": \"year\",\n",
        "      \"ProjectRDC\": \"agency\"\n",
        "    }) # rename columns for my own sake\n",
        "    rdc_data[\"year\"] = rdc_data[\"year\"].fillna(\"\").astype(str) # add NaN if year is unspecified\n",
        "    rdc_data[\"keywords\"] = \"\" # make an empty column for keywords (TBD)\n",
        "    output_file = \"data_extracted.csv\" # make an empty csv file\n",
        "    rdc_data.to_csv(output_file, index=False) # save the selected data into the new csv file\n",
        "\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: The file '{file_name}' was not found. Please check the file path.\")\n",
        "\n",
        "except ValueError as e:\n",
        "  print(f\"Error: {e}. Check if the sheet name '{sheet_name}' exists in the file.\")\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"Unexpected error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the environment for the extraction of keywords."
      ],
      "metadata": {
        "id": "5tcRR_2ndfDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keybert"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Fsj5Mcfzczvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keybert import KeyBERT # import keybert for keyword extraction\n",
        "kw_model = KeyBERT() # initialize the model"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CSLKJUYDdsFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract keywords using `keyBERT` and add them to the initially empty column `keywords`."
      ],
      "metadata": {
        "id": "cRFpSfJRf89N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('data_extracted.csv') # read the csv file\n",
        "\n",
        "df2[\"title\"] = df2[\"title\"].astype(str).fillna(\"\") # make sure all titles are strings + prevent the NaN exception\n",
        "for index, row in df2.iterrows(): # iterate through each row in the dataframe\n",
        "  title = row['title'] # get the title of the row from which we can extract keywords\n",
        "  keywords = kw_model.extract_keywords(title, keyphrase_ngram_range=(1, 1), stop_words='english', top_n=5) # extract top 5 keywords from the title\n",
        "  formatted_keywords = \"; \".join([kw[0] for kw in keywords]) # store the keywords as desired\n",
        "  print(formatted_keywords)\n",
        "  df2.loc[index, 'keywords'] = formatted_keywords # update cell\n",
        "\n",
        "df2[\"year\"] = df2[\"year\"].fillna(0).astype(int).replace(0, \"\") # makes my year into a number because omg\n",
        "df2.to_csv(\"data_with_keywords.csv\", index=False)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ShpCLOktfmAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storing Structures"
      ],
      "metadata": {
        "id": "Oqwddr3FlnM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Class `Publications`\n",
        "\n",
        "We chose to store all data for each publication inside a class for easier retrieval thanks to the dot operators (e.g. `publication.property`). This allowed us to construct more flexible traversal functions, which can then easily be adjusted for the purpose (i.e. only minor adjustments are necessary if one wishes to traverse for different properties such as `year` or `keywords`). All created publication objects are stored in a list titled `publications` for simple traversal."
      ],
      "metadata": {
        "id": "CrJd7_I5mPk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Publication:\n",
        "  def __init__(self, title, year, agency, keywords):\n",
        "     self.title = str(title)\n",
        "     self.year = self.safe_int(year)\n",
        "     self.agency = str(agency)\n",
        "     self.keywords = str(keywords)\n",
        "\n",
        "  def safe_int(self, value):\n",
        "    try:\n",
        "        return int(value)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "  def __lt__(self, other):\n",
        "    # sort by title (alphabetically)\n",
        "    if self.title != other.title:\n",
        "        return self.title < other.title\n",
        "    return self.year < other.year\n",
        "\n",
        "  def __repr__(self):\n",
        "    # represent publication w title by default\n",
        "    return f\"Publication(title='{self.title}', year={self.year})\""
      ],
      "metadata": {
        "id": "IakunadRlvLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialise a `Publication` object for each row and store them in a list titled `publication`."
      ],
      "metadata": {
        "id": "1cKmCFzKmTwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "publications = []\n",
        "for index, row in df2.iterrows():\n",
        "  publication = Publication(row['title'], row['year'], row['agency'], row['keywords'])\n",
        "  publications.append(publication)"
      ],
      "metadata": {
        "id": "WHSM7OTmm7LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph"
      ],
      "metadata": {
        "id": "P8kr6w7wnqpt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialise graph with all items from `publications` as nodes."
      ],
      "metadata": {
        "id": "uKUr8MOtooTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx # import library for making graph\n",
        "\n",
        "G = nx.MultiGraph() # initialise graph, must be multigraph because I need multiple eedges of multiple colours\n",
        "G.add_nodes_from(publications) # add publications as nodes\n"
      ],
      "metadata": {
        "id": "tPSxRtRCnuqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add edges when there is a relation between two publications. In this section, an embedded `for` loop compares every publication with every other publication in the graph and stores `true` if there is similarity. This temporary list of conditions get subsequently passed onto another `for` loop which finally greates an edge of an appropriate colour between these two publications. Add green edges for a relation between titles, red for a relation between years, blue for a relation between agencies, and purple for a relation between keywrods."
      ],
      "metadata": {
        "id": "RBYkAoGYop8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edge_colours = {\n",
        "    \"title\": \"green\",\n",
        "    \"year\": \"red\",\n",
        "    \"agency\": \"blue\",\n",
        "    \"keyword\": \"purple\"\n",
        "}\n",
        "\n",
        "for publication in publications:\n",
        "  for another_publication in publications: # compare every publication with every publication\n",
        "    if publication is another_publication: # ignore if it's the same publication (doesn't need comparison])\n",
        "      continue\n",
        "    conditions = [ # check if title, year, agency or at least one keyword is alike\n",
        "      (publication.title == another_publication.title, \"title\"),\n",
        "      (publication.year == another_publication.year, \"year\"),\n",
        "      (publication.agency == another_publication.agency, \"agency\"),\n",
        "      (any(keyword in another_publication.keywords for keyword in publication.keywords.split(\"; \")), \"keyword\")\n",
        "    ]\n",
        "\n",
        "    for condition, colour_label in conditions:\n",
        "      if condition: # if title, year, agency or at least one keyword is alike, add edge\n",
        "        G.add_edge(publication, another_publication, colour=edge_colours[colour_label])"
      ],
      "metadata": {
        "id": "nGBbM52Oo9xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph Statistics**"
      ],
      "metadata": {
        "id": "PVdVA9bb77kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# return connected components for a subgraph of a particular colour\n",
        "def count_colored_connected_components(G, colour):\n",
        "  # get connected nodes given colour\n",
        "  subgraph = G.edge_subgraph([(u, v, k) for u, v, k, data in G.edges(data=True, keys=True) if data.get(\"colour\") == colour]).copy()\n",
        "\n",
        "  # include isolated nodes\n",
        "  for node in G.nodes():\n",
        "    # make sure that we're not counting None as a separate component (though this is probably useless)\n",
        "    attribute_name = next((key for key, value in edge_colours.items() if value == colour), None)\n",
        "    if attribute_name and getattr(node, attribute_name, None) is not None:\n",
        "      if any(data.get(\"colour\") != colour for _, _, data in G.edges(node, data=True)):\n",
        "        subgraph.add_node(node)  # add isolated node\n",
        "\n",
        "\n",
        "  return len(list(nx.connected_components(subgraph)))"
      ],
      "metadata": {
        "id": "JhxPMaN3DccK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_nodes = len(G.nodes())\n",
        "total_edges = len(G.edges())\n",
        "edges_green = len([(u, v) for u, v, data in G.edges(data=True) if data.get(\"colour\") == \"green\"])\n",
        "edges_red = len([(u, v) for u, v, data in G.edges(data=True) if data.get(\"colour\") == \"red\"])\n",
        "edges_blue = len([(u, v) for u, v, data in G.edges(data=True) if data.get(\"colour\") == \"blue\"])\n",
        "edges_purple = len([(u, v) for u, v, data in G.edges(data=True) if data.get(\"colour\") == \"purple\"])\n",
        "number_connected_components_green = count_colored_connected_components(G, \"green\")\n",
        "number_connected_components_red = count_colored_connected_components(G, \"red\")\n",
        "number_connected_components_blue = count_colored_connected_components(G, \"blue\")\n",
        "number_connected_components_purple = count_colored_connected_components(G, \"purple\")\n",
        "\n",
        "\n",
        "print(f\"Total nodes: {total_nodes}\")\n",
        "print(f\"Total edges: {total_edges}\")\n",
        "print(f\"Edges with colour 'green': {edges_green}\")\n",
        "print(f\"Edges with colour 'red': {edges_red}\")\n",
        "print(f\"Edges with colour 'blue': {edges_blue}\")\n",
        "print(f\"Edges with colour 'purple': {edges_purple}\")\n",
        "print(f\"Number of connected components (green edges): {number_connected_components_green}\")\n",
        "print(f\"Number of connected components (red edges): {number_connected_components_red}\")\n",
        "print(f\"Number of connected components (blue edges): {number_connected_components_blue}\")\n",
        "print(f\"Number of connected components (purple edges): {number_connected_components_purple}\")"
      ],
      "metadata": {
        "id": "5Cxd53SG6G7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot**\n",
        "\n",
        "This plot shows all nodes (title and year) and their relation to one another in the overall graph. `selected_colour` determines the graph of what is being depicted for clarity (i.e. year, title, agency, or keyword connection), but the argument can be removed an all graph can be plotted. The overall plot is a bit cluttered as the dataset contains 1735 rows all of which become their individual nodes, and so we only select a pre-defined sample size."
      ],
      "metadata": {
        "id": "C3UFjRaWC7qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connected by Year (Red)**"
      ],
      "metadata": {
        "id": "ZuKVsyiE_m0M"
      }
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# sample a fixed number of nodes\n",
        "sample_size = 50\n",
        "selected_colour = \"red\"\n",
        "\n",
        "# sample random nodes for quick convenient plot\n",
        "sampled_nodes = random.sample(list(G.nodes()), min(len(G.nodes()), sample_size))\n",
        "\n",
        "# find all edges between the selected node that have the prespecified colour\n",
        "filtered_edges = [\n",
        "  (u, v) for u, v, data in G.edges(data=True)\n",
        "  if data.get(\"colour\") == selected_colour and u in sampled_nodes and v in sampled_nodes\n",
        "]\n",
        "\n",
        "# make a subgraph of these\n",
        "sampled_subgraph = nx.Graph()\n",
        "sampled_subgraph.add_nodes_from(sampled_nodes)\n",
        "sampled_subgraph.add_edges_from(filtered_edges)\n",
        "\n",
        "# add labels\n",
        "node_labels = {node: f\"{node.title[:20]}...\\n({node.year})\" for node in sampled_subgraph.nodes()} # cut title to make it prettier\n",
        "\n",
        "# plot the subgraph\n",
        "default_node_positions = nx.spring_layout(sampled_subgraph, k=0.5, seed=102)  # generate consistent layout, modify k to individual CCs closer together\n",
        "plt.figure(figsize=(10, 10))\n",
        "edge_colors = [G[u][v].get(\"colour\", \"black\") for u, v in sampled_subgraph.edges()]\n",
        "nx.draw(\n",
        "  sampled_subgraph,\n",
        "  pos=default_node_positions,\n",
        "  with_labels=True,\n",
        "  labels=node_labels,\n",
        "  node_size=100,\n",
        "  edge_color=selected_colour,\n",
        "  font_size=8\n",
        ")\n",
        "plt.title(f\"Subgraph of {sample_size} Random Nodes with {selected_colour.capitalize()} Edges\")\n",
        "plt.show()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "47B_7I9j8zWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connected by Title (Green)**"
      ],
      "metadata": {
        "id": "PaRp8nUR_2IT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# sample a fixed number of nodes\n",
        "sample_size = 200\n",
        "selected_colour = \"green\"\n",
        "\n",
        "# sample random nodes for quick convenient plot\n",
        "sampled_nodes = random.sample(list(G.nodes()), min(len(G.nodes()), sample_size))\n",
        "\n",
        "# find all edges between the selected node that have the prespecified colour\n",
        "filtered_edges = [\n",
        "  (u, v) for u, v, data in G.edges(data=True)\n",
        "  if data.get(\"colour\") == selected_colour and u in sampled_nodes and v in sampled_nodes\n",
        "]\n",
        "\n",
        "# make a subgraph of these\n",
        "sampled_subgraph = nx.Graph()\n",
        "sampled_subgraph.add_nodes_from(sampled_nodes)\n",
        "sampled_subgraph.add_edges_from(filtered_edges)\n",
        "\n",
        "# add labels\n",
        "node_labels = {node: f\"{node.title[:20]}...\" for node in sampled_subgraph.nodes()} # cut title to make it prettier\n",
        "\n",
        "# plot the subgraph\n",
        "default_node_positions = nx.spring_layout(sampled_subgraph, k=0.3, seed=102)  # generate consistent layout, modify k to individual CCs closer together\n",
        "plt.figure(figsize=(10, 10))\n",
        "edge_colors = [G[u][v].get(\"colour\", \"black\") for u, v in sampled_subgraph.edges()]\n",
        "nx.draw(\n",
        "  sampled_subgraph,\n",
        "  pos=default_node_positions,\n",
        "  with_labels=True,\n",
        "  labels=node_labels,\n",
        "  node_size=100,\n",
        "  edge_color=selected_colour,\n",
        "  font_size=8\n",
        ")\n",
        "plt.title(f\"Subgraph of {sample_size} Random Nodes with {selected_colour.capitalize()} Edges\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xksZMf2x_9bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connected by Agency (Blue)**"
      ],
      "metadata": {
        "id": "y7wDVRvaAHg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# sample a fixed number of nodes\n",
        "sample_size = 50\n",
        "selected_colour = \"blue\"\n",
        "\n",
        "# sample random nodes for quick convenient plot\n",
        "sampled_nodes = random.sample(list(G.nodes()), min(len(G.nodes()), sample_size))\n",
        "\n",
        "# find all edges between the selected node that have the prespecified colour\n",
        "filtered_edges = [\n",
        "  (u, v) for u, v, data in G.edges(data=True)\n",
        "  if data.get(\"colour\") == selected_colour and u in sampled_nodes and v in sampled_nodes\n",
        "]\n",
        "\n",
        "# make a subgraph of these\n",
        "sampled_subgraph = nx.Graph()\n",
        "sampled_subgraph.add_nodes_from(sampled_nodes)\n",
        "sampled_subgraph.add_edges_from(filtered_edges)\n",
        "\n",
        "# add labels\n",
        "node_labels = {node: f\"{node.title[:20]}...\\n({node.agency})\" for node in sampled_subgraph.nodes()} # cut title to make it prettier\n",
        "\n",
        "# plot the subgraph\n",
        "default_node_positions = nx.spring_layout(sampled_subgraph, k=0.9, seed=102)  # generate consistent layout, modify k to individual CCs closer together\n",
        "plt.figure(figsize=(10, 10))\n",
        "edge_colors = [G[u][v].get(\"colour\", \"black\") for u, v in sampled_subgraph.edges()]\n",
        "nx.draw(\n",
        "  sampled_subgraph,\n",
        "  pos=default_node_positions,\n",
        "  with_labels=True,\n",
        "  labels=node_labels,\n",
        "  node_size=100,\n",
        "  edge_color=selected_colour,\n",
        "  font_size=8\n",
        ")\n",
        "plt.title(f\"Subgraph of {sample_size} Random Nodes with {selected_colour.capitalize()} Edges\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7f00Vr1tAG-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connected by Keyword (Purple)**"
      ],
      "metadata": {
        "id": "LrdZV_d-_tq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# sample a fixed number of nodes\n",
        "sample_size = 50\n",
        "selected_colour = \"purple\"\n",
        "\n",
        "# sample random nodes for quick convenient plot\n",
        "sampled_nodes = random.sample(list(G.nodes()), min(len(G.nodes()), sample_size))\n",
        "\n",
        "# find all edges between the selected node that have the prespecified colour\n",
        "filtered_edges = [\n",
        "  (u, v) for u, v, data in G.edges(data=True)\n",
        "  if data.get(\"colour\") == selected_colour and u in sampled_nodes and v in sampled_nodes\n",
        "]\n",
        "\n",
        "# make a subgraph of these\n",
        "sampled_subgraph = nx.Graph()\n",
        "sampled_subgraph.add_nodes_from(sampled_nodes)\n",
        "sampled_subgraph.add_edges_from(filtered_edges)\n",
        "\n",
        "# add labels\n",
        "node_labels = {node: f\"{node.title[:20]}...\\n{node.year}\" for node in sampled_subgraph.nodes()} # cut title to make it prettier\n",
        "\n",
        "# plot the subgraph\n",
        "default_node_positions = nx.spring_layout(sampled_subgraph, k=0.5, seed=102)  # generate consistent layout, modify k to individual CCs closer together\n",
        "plt.figure(figsize=(10, 10))\n",
        "edge_colors = [G[u][v].get(\"colour\", \"black\") for u, v in sampled_subgraph.edges()]\n",
        "nx.draw(\n",
        "  sampled_subgraph,\n",
        "  pos=default_node_positions,\n",
        "  with_labels=True,\n",
        "  labels=node_labels,\n",
        "  node_size=100,\n",
        "  edge_color=selected_colour,\n",
        "  font_size=8\n",
        ")\n",
        "plt.title(f\"Subgraph of {sample_size} Random Nodes with {selected_colour.capitalize()} Edges\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8rq-Eqkr_yCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search & Traverse"
      ],
      "metadata": {
        "id": "ZD3ol4VqsK-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Breadth-First Search**\n",
        "\n",
        "Looks through all neighbours first before moving on to the next node."
      ],
      "metadata": {
        "id": "wuEFkRG72u03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "def bfs(graph, start_publication, label):\n",
        "  # copy dict of keys x colours\n",
        "  edge_colours = {\n",
        "      \"title\": \"green\",\n",
        "      \"year\": \"red\",\n",
        "      \"agency\": \"blue\",\n",
        "      \"keyword\": \"purple\"\n",
        "  }\n",
        "\n",
        "  # only get relevant edges (e.g. when searching for publications related by \"year\", there is no need to store \"agency\" etc.)\n",
        "  select_edges = {(u, v) for u, v, data in graph.edges(data=True) if data.get(\"colour\") == edge_colours[label]}\n",
        "\n",
        "  # make a new subgraph with only relevant edges\n",
        "  new_graph = nx.Graph()\n",
        "  new_graph.add_nodes_from(graph.nodes())  # need all nodes\n",
        "  new_graph.add_edges_from(select_edges)   # need only selected edges\n",
        "\n",
        "  # init bfs structures\n",
        "  visited = set()  # track unique visited nodes\n",
        "  queue = deque([start_publication])  # bfs queue\n",
        "  traversal_order = []  # track traversal\n",
        "\n",
        "  # bfs loop\n",
        "  while queue:\n",
        "    current_publication = queue.popleft()\n",
        "    if current_publication not in visited:\n",
        "      visited.add(current_publication)\n",
        "      traversal_order.append(current_publication)\n",
        "\n",
        "      # add all unvisited neighbours\n",
        "      for neighbour in sorted(new_graph.neighbors(current_publication)):\n",
        "        if neighbour not in visited:\n",
        "          queue.append(neighbour)\n",
        "  return traversal_order\n"
      ],
      "metadata": {
        "id": "YwleVaZ_sS4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [f.title for f in bfs(G, publications[4], \"keyword\")]\n",
        "print(lst)"
      ],
      "metadata": {
        "id": "Vmk3P_Eq9S2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Depth-First Search**\n",
        "\n",
        "Commits to a neighbour and searches the selected neighbour first before looking at the next neighbour."
      ],
      "metadata": {
        "id": "hmuubYgpWWF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dfs(graph, start_publication, label):\n",
        "  # copy dict of keys x colours\n",
        "  edge_colours = {\n",
        "      \"title\": \"green\",\n",
        "      \"year\": \"red\",\n",
        "      \"agency\": \"blue\",\n",
        "      \"keyword\": \"purple\"\n",
        "  }\n",
        "\n",
        "  # only get relevant edges (e.g. when searching for publications related by \"year\", there is no need to store \"agency\" etc.)\n",
        "  select_edges = {(u, v) for u, v, data in graph.edges(data=True) if data.get(\"colour\") == edge_colours[label]}\n",
        "\n",
        "  # make a new subgraph with only relevant edges\n",
        "  new_graph = nx.Graph()\n",
        "  new_graph.add_nodes_from(graph.nodes())  # need all nodes\n",
        "  new_graph.add_edges_from(select_edges)   # need only selected edges\n",
        "\n",
        "  visited = set()\n",
        "  stack = [start_publication]\n",
        "  traversal_order = []\n",
        "\n",
        "  while stack:\n",
        "    current_node = stack.pop()\n",
        "    if current_node not in visited:\n",
        "      visited.add(current_node)\n",
        "      traversal_order.append(current_node)\n",
        "\n",
        "      neighbors = sorted(new_graph.neighbors(current_node))\n",
        "      for neighbor in reversed(neighbors):\n",
        "        if neighbor not in visited:\n",
        "          stack.append(neighbor)\n",
        "\n",
        "  return traversal_order"
      ],
      "metadata": {
        "id": "2c37UJsWWX_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [f.title for f in dfs(G, publications[1], \"keyword\")]\n",
        "print(lst)"
      ],
      "metadata": {
        "id": "R_N6_Pk6XOwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests"
      ],
      "metadata": {
        "id": "lUq6T1kaMC74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "# here I test if the graph builds properly\n",
        "class TestGraphEdges(unittest.TestCase):\n",
        "\n",
        "  def test_edge_exists(self):\n",
        "    self.assertTrue(G.has_edge(publications[0], publications[3]), f\"Edge should exist between '{publications[0].title}' and '{publications[3].title}', but it was NOT found.\")\n",
        "\n",
        "  def test_edge_does_not_exist(self):\n",
        "    self.assertFalse(G.has_edge(publications[94], publications[95]), f\"Edge should NOT exist between '{publications[104].title}' and '{publications[105].title}', but it was found.\")\n",
        "\n",
        "  def test_edge_colour(self):\n",
        "    edges = [attr[\"colour\"] for k, attr in G[publications[6]][publications[7]].items()]\n",
        "    self.assertIn(\"green\", edges, \"No green edge found between these nodes!\")\n",
        "\n",
        "  def test_edge_colour_again(self):\n",
        "    edges = [attr[\"colour\"] for k, attr in G[publications[980]][publications[1235]].items()]\n",
        "    self.assertNotIn(\"red\", edges, \"No red edge found between these nodes!\")\n",
        "\n",
        "  def test_connected_components_year(self):\n",
        "    df = pd.read_csv(\"data_with_keywords.csv\")\n",
        "    self.assertEqual(count_colored_connected_components(G, \"red\"), df[\"year\"].nunique() + 1, \"Connected components incorrect\") # +1 for empty\n",
        "\n",
        "  def test_connected_components_agency(self):\n",
        "    df = pd.read_csv(\"data_with_keywords.csv\")\n",
        "    self.assertEqual(count_colored_connected_components(G, \"blue\"), df[\"agency\"].nunique(), \"Connected components incorrect\")\n",
        "\n",
        "# here I test if the search works as expected\n",
        "class GraphTestBase(unittest.TestCase):\n",
        "  def setUp(self):\n",
        "    # make a simple graph to easily test the output\n",
        "    self.G = nx.Graph()\n",
        "    self.G.add_nodes_from([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"])\n",
        "    self.G.add_edges_from([\n",
        "        (\"A\", \"B\", {\"colour\": \"red\"}),\n",
        "        (\"A\", \"C\", {\"colour\": \"red\"}),\n",
        "        (\"A\", \"D\", {\"colour\": \"red\"}),\n",
        "        (\"B\", \"E\", {\"colour\": \"red\"}),\n",
        "        (\"C\", \"F\", {\"colour\": \"blue\"}),\n",
        "        (\"D\", \"G\", {\"colour\": \"red\"}),\n",
        "    ])\n",
        "\n",
        "class TestGraphTraversal(GraphTestBase):\n",
        "  def test_bfs_traversal(self):\n",
        "    expected_traversal = [\"A\", \"B\", \"C\", \"D\", \"E\", \"G\"]\n",
        "    result = bfs(self.G, \"A\", \"year\")\n",
        "    self.assertEqual(result, expected_traversal)\n",
        "\n",
        "  def test_dfs_traversal(self):\n",
        "    expected_traversal = [\"A\", \"B\", \"E\", \"C\", \"D\", \"G\"]\n",
        "    result = dfs(self.G, \"A\", \"year\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "metadata": {
        "id": "a6W8sRvoMCX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}